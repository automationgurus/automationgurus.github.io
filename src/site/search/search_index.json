{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome in Automation Bible Mission provide high-quality content investigate new areas be first Who are we? Artur Brodzi\u0144ski Kamil Wi\u0119cek","title":"Welcome in Automation Bible"},{"location":"#welcome-in-automation-bible","text":"","title":"Welcome in Automation Bible"},{"location":"#mission","text":"provide high-quality content investigate new areas be first","title":"Mission"},{"location":"#who-are-we","text":"","title":"Who are we?"},{"location":"#artur-brodzinski","text":"","title":"Artur Brodzi\u0144ski"},{"location":"#kamil-wiecek","text":"","title":"Kamil Wi\u0119cek"},{"location":"about-us/","text":"","title":"About us"},{"location":"azure-devops-audit-logs-forwarding/","text":"Forward Azure DevOps Audit Logs to Log Analytics Workspace Is Log Analytics Workspace clairvoyant? No it isn't! Therefore, we developed an automated solution that is continuously streaming audit logs from Azure DevOps to Log Analytics Workspace. Let's start from demo. Modify the branch policy and start to be suspicious. Invoke synchronization manually or wait. Check the results. What is available out of the box? Browsing logs through web portal. Exporting them to JSON/ CSV Analyze them using Excel/ custom tools. More general information about Azure DevOps Auditing is available in the link below. It's not our purpose to paraphrase MS documentation. Please read the following part of their documentation to get more details about ADO auditing in general. You can find more details here! Acronyms and abbreviations ADO - Azure DevOps ORG - Azure DevOps Organization PAT - Personal Access Token from ADO AAA - Azure Automation Account ARA - Azure Run As Account AKV - Azure Key Vault LAW - Azure Log Analytics Workspace Who are you? We assume that... PS C:\\> $You.SessionLevelReadiness -GE 200 True ... so we're not providing detailed, step by step instructions on how to create every single resource required to deploy this solution. We believe that you can deploy and configure them without additional instructions, or you're able to find them on your own. Prepare infrastructure Here are required resources and it's the configuration required to deploy the described solution: Organization in Azure DevOps with enabled auditing. Personal Access Token with read audit log events, manage and delete streams scope. Azure Automation Account with Azure Run As Account . AAA string variables named KeyVaultName, WorkspaceId, OrganizationName AAA string variable named LastAzureDevOpsSyncDate with round-trip date/time pattern value (for example 2020-01-01T00:00:00.0000001Z ) Azure Key Vault AKV Get and list secret access policy for ARA. AzureDevOpsPersonalAccessToken secret in AKV containing PAT value. Azure Log Analytics Workspace. Shared key read permissions for ARA. Azure Automation Powershell SynchronizeAzureDevOpsAuditLogs Runbook ( get it here ) Solution overview. More details. Every single hour Azure Automation Runbook (AAC) is invoked by schedule. Set context. All actions are performed in the context of Azure Run As Account . This account was created during Automation Account creation. Get parameters (read details above). Get all ADO audit logs entries between LastAzureDevOpsSyncDate and current date and time. Upload event to Log Analytics Workspace via REST API call. Update LastAzureDevOpsSyncDate . Solution parameters Script Parameter Source/ Where you should set it $KeyVaultName KeyVaultName variable from Automation Account $StartTime LastAzureDevOpsSyncDate variable from Automation Account $OrganizationName OrganizationName variable from Automation Account $CustomerId WorkspaceId variable from Automation Account $PersonAccessToken AzureDevOpsPersonalAccessToken secret from Azure KeyVault $SharedKey SharedKey property from Log Analytics Workspace (Id = $CustomerId) Powershell Runbook Get SynchronizeAzureDevOpsAuditLogsRunbook Source Code We use Build-Signature and Post-LogAnalyticsData from MS DOCS: Data collector api . In this example, they use $TimeStampField variable that is global. It isn't good practice to use in function variables defined out of function scope. We replaced that. Function Build-Signature ( $customerId , $sharedKey , $date , $contentLength , $method , $contentType , $resource ) { $xHeaders = \"x-ms-date:\" + $date $stringToHash = $method + \" `n \" + $contentLength + \" `n \" + $contentType + \" `n \" + $xHeaders + \" `n \" + $resource $bytesToHash = [Text.Encoding] :: UTF8 . GetBytes ( $stringToHash ) $keyBytes = [Convert] :: FromBase64String ( $sharedKey ) $sha256 = New-Object System . Security . Cryptography . HMACSHA256 $sha256 . Key = $keyBytes $calculatedHash = $sha256 . ComputeHash ( $bytesToHash ) $encodedHash = [Convert] :: ToBase64String ( $calculatedHash ) $authorization = 'SharedKey {0}:{1}' -f $customerId , $encodedHash return $authorization } Function Post-LogAnalyticsData ( $ustomerId , $sharedKey , $body , $logType ) { $method = \"POST\" $contentType = \"application/json\" $resource = \"/api/logs\" $rfc1123date = [DateTime] :: UtcNow . ToString ( \"r\" ) $contentLength = $body . Length $signature = Build-Signature ` -customerId $customerId ` -sharedKey $sharedKey ` -date $rfc1123date ` -contentLength $contentLength ` -method $method ` -contentType $contentType ` -resource $resource $uri = \"https://\" + $customerId + \".ods.opinsights.azure.com\" + $resource + \"?api-version=2016-04-01\" $headers = @{ \"Authorization\" = $signature ; \"Log-Type\" = $logType ; \"x-ms-date\" = $rfc1123date ; \"time-generated-field\" = \"timestamp\" ; } $response = Invoke-WebRequest -Uri $uri -Method $method -ContentType $contentType -Headers $headers -Body $body -UseBasicParsing return $response . StatusCode } $LogType = \"AzureDevOps\" $Conn = Get-AutomationConnection -Name AzureRunAsConnection Connect-AzAccount -ServicePrincipal -Tenant $Conn . TenantID -ApplicationId $Conn . ApplicationID -CertificateThumbprint $Conn . CertificateThumbprint | Out-Null Select-AzSubscription -SubscriptionId $Conn . SubscriptionID | Out-Null $KeyVaultName = Get-AutomationVariable -Name KeyVaultName Write-Output -InputObject 'Get keyvault name from automation account variables - success' $OrganizationName = Get-AutomationVariable -Name OrganizationName Write-Output -InputObject 'Get Azure DevOps organization name from automation account variables - success' $CustomerId = Get-AutomationVariable -Name WorkspaceId Write-Output -InputObject 'Get Log Analytics Workspace Id from automation account variables - success' $LogAnalyticsWorkspace = Get-AzOperationalInsightsWorkspace | Where-Object -Property CustomerId -EQ $CustomerId $SharedKey = ( Get-AzOperationalInsightsWorkspaceSharedKey -ResourceGroupName $logAnalyticsWorkspace . ResourceGroupName -Name $logAnalyticsWorkspace . Name ). PrimarySharedKey Write-Output -InputObject \"Get shared key directly from ' $( $logAnalyticsWorkspace . Name ) - success\" $PersonAccessToken = ( Get-AzKeyVaultSecret -VaultName $KeyVaultName -Name 'AzureDevOpsPersonalAccessToken' ). SecretValueText Write-Output -InputObject \"Get Personal Access Token from key vault ' $( $KeyVaultName ) ' - success\" $StartTime = Get-AutomationVariable -Name LastAzureDevOpsSyncDate $StartTime = $StartTime . ToUniversalTime (). GetDateTimeFormats ( \"o\" ) [string] $EndTimeQuery = [DateTime] :: Now . ToUniversalTime (). GetDateTimeFormats ( \"o\" ) Write-Output -InputObject \"Script will look for audi events created between $( $StartTime ) and $( $endTimeQuery ) \" $Base64AuthInfo = [Convert] :: ToBase64String ( [Text.Encoding] :: ASCII . GetBytes (( \"{0}:{1}\" -f 'basic' , $PersonAccessToken ))) $Headers = @{ Authorization = \"Basic $Base64AuthInfo\" } [array] $ApiOutputs = @() [string] $ContinuationToken = '' do { $EndpointUri = \"https://auditservice.dev.azure.com/ $( $OrganizationName ) /_apis/audit/auditlog?api-version=5.1-preview.1\" $EndpointUri += \"&batchSize=200\" $EndpointUri += \"&skipAggregation=true\" $EndpointUri += \"&startTime= $( $StartTime ) \" $EndpointUri += \"&endTime= $( $endTimeQuery ) \" if ( $ContinuationToken ) { $EndpointUri += \"&continuationToken= $( $continuationToken ) \" } $ApiOutput = Invoke-RestMethod -Uri $endpointUri -Headers $headers -Method Get $ContinuationToken = $ApiOutput . continuationToken #tu $ApiOutputs += $ApiOutput } while ( $ApiOutput . hasMore ) [array] $DecoratedAuditLogEntries = $ApiOutputs . decoratedAuditLogEntries if ( -not $DecoratedAuditLogEntries ) { Write-Output -InputObject 'There are no new audit logs.' return ; } Write-Output -InputObject \"Found $( $DecoratedAuditLogEntries . Count ) new audit entries\" foreach ( $item in $DecoratedAuditLogEntries ) { $item . data = $item . data | ConvertTo-Json -Compress -Depth 100 } $RecordsJson = $DecoratedAuditLogEntries | ` Select-Object -ExcludeProperty actorImageUrl | ` ConvertTo-Json $StatusCode = Post-LogAnalyticsData -customerId $CustomerId -sharedKey $SharedKey -body ( [System.Text.Encoding] :: UTF8 . GetBytes ( $recordsJson )) -logType $LogType if ( $StatusCode -eq 200 ){ Set-AutomationVariable -Name LastAzureDevOpsSyncDate -Value $endTimeQuery Write-Output -InputObject 'Azure DevOps audi logs forwarding completed successfully' } It's time to rest and check what we did You've just discovered new extension installed. You wonder who and when did install this AzSK Extension, so you ask Log Analytics. AzureDevOps_CL | sort by TimeGenerated desc nulls last | where actionId_s == \"Extension.Installed\" | project TimeGenerated, actionId_s, scopeDisplayName_s , details_s, actorDisplayName_s TimeGenerated actionId_s scopeDisplayName_s details_s actorDisplayName_s 2020-03-15T16:47:19.367Z Extension.Installed AutomationGuyIO (Organization) Extension \"Secure DevOps Kit (AzSK) CICD Extensions for Azure\" from publisher \"Microsoft DevLabs\" was installed - Version \"3.1.7\" Automation Guru Solution development insights ARA becomes a Contributor by default. Consider changing that. Storing LAW SharedKey in AKV is one of the options, but it'll force you to update it on change. We decided to get it directly during the script execution. We could use AAA encrypted value to store PAT, but in case of storing secrets, AKV should always be the primary choice. Other parameters we don't consider as secrets, so we store them in AAA variables. Enabling Allow trusted Microsoft services to bypass this firewall in AKW Networking configuration didn't allow access from AAA. Therefore we set this setting to Allow access from all networks . Visit also Dominic Batstone's Blog: Export ADO Audit Logs and query them with LogParser mohitgoyal.co: Working with Audit logs in Azure DevOps","title":"Azure DevOps Audit Logs Forwarder"},{"location":"azure-devops-audit-logs-forwarding/#forward-azure-devops-audit-logs-to-log-analytics-workspace","text":"","title":"Forward Azure DevOps Audit Logs to Log Analytics Workspace"},{"location":"azure-devops-audit-logs-forwarding/#is-log-analytics-workspace-clairvoyant","text":"No it isn't! Therefore, we developed an automated solution that is continuously streaming audit logs from Azure DevOps to Log Analytics Workspace.","title":"Is Log Analytics Workspace clairvoyant?"},{"location":"azure-devops-audit-logs-forwarding/#lets-start-from-demo","text":"Modify the branch policy and start to be suspicious. Invoke synchronization manually or wait. Check the results.","title":"Let's start from demo."},{"location":"azure-devops-audit-logs-forwarding/#what-is-available-out-of-the-box","text":"Browsing logs through web portal. Exporting them to JSON/ CSV Analyze them using Excel/ custom tools. More general information about Azure DevOps Auditing is available in the link below. It's not our purpose to paraphrase MS documentation. Please read the following part of their documentation to get more details about ADO auditing in general. You can find more details here!","title":"What is available out of the box?"},{"location":"azure-devops-audit-logs-forwarding/#acronyms-and-abbreviations","text":"ADO - Azure DevOps ORG - Azure DevOps Organization PAT - Personal Access Token from ADO AAA - Azure Automation Account ARA - Azure Run As Account AKV - Azure Key Vault LAW - Azure Log Analytics Workspace","title":"Acronyms and abbreviations"},{"location":"azure-devops-audit-logs-forwarding/#who-are-you","text":"We assume that... PS C:\\> $You.SessionLevelReadiness -GE 200 True ... so we're not providing detailed, step by step instructions on how to create every single resource required to deploy this solution. We believe that you can deploy and configure them without additional instructions, or you're able to find them on your own.","title":"Who are you?"},{"location":"azure-devops-audit-logs-forwarding/#prepare-infrastructure","text":"Here are required resources and it's the configuration required to deploy the described solution: Organization in Azure DevOps with enabled auditing. Personal Access Token with read audit log events, manage and delete streams scope. Azure Automation Account with Azure Run As Account . AAA string variables named KeyVaultName, WorkspaceId, OrganizationName AAA string variable named LastAzureDevOpsSyncDate with round-trip date/time pattern value (for example 2020-01-01T00:00:00.0000001Z ) Azure Key Vault AKV Get and list secret access policy for ARA. AzureDevOpsPersonalAccessToken secret in AKV containing PAT value. Azure Log Analytics Workspace. Shared key read permissions for ARA. Azure Automation Powershell SynchronizeAzureDevOpsAuditLogs Runbook ( get it here )","title":"Prepare infrastructure"},{"location":"azure-devops-audit-logs-forwarding/#solution-overview-more-details","text":"Every single hour Azure Automation Runbook (AAC) is invoked by schedule. Set context. All actions are performed in the context of Azure Run As Account . This account was created during Automation Account creation. Get parameters (read details above). Get all ADO audit logs entries between LastAzureDevOpsSyncDate and current date and time. Upload event to Log Analytics Workspace via REST API call. Update LastAzureDevOpsSyncDate .","title":"Solution overview. More details."},{"location":"azure-devops-audit-logs-forwarding/#solution-parameters","text":"Script Parameter Source/ Where you should set it $KeyVaultName KeyVaultName variable from Automation Account $StartTime LastAzureDevOpsSyncDate variable from Automation Account $OrganizationName OrganizationName variable from Automation Account $CustomerId WorkspaceId variable from Automation Account $PersonAccessToken AzureDevOpsPersonalAccessToken secret from Azure KeyVault $SharedKey SharedKey property from Log Analytics Workspace (Id = $CustomerId)","title":"Solution parameters"},{"location":"azure-devops-audit-logs-forwarding/#powershell-runbook","text":"Get SynchronizeAzureDevOpsAuditLogsRunbook Source Code We use Build-Signature and Post-LogAnalyticsData from MS DOCS: Data collector api . In this example, they use $TimeStampField variable that is global. It isn't good practice to use in function variables defined out of function scope. We replaced that. Function Build-Signature ( $customerId , $sharedKey , $date , $contentLength , $method , $contentType , $resource ) { $xHeaders = \"x-ms-date:\" + $date $stringToHash = $method + \" `n \" + $contentLength + \" `n \" + $contentType + \" `n \" + $xHeaders + \" `n \" + $resource $bytesToHash = [Text.Encoding] :: UTF8 . GetBytes ( $stringToHash ) $keyBytes = [Convert] :: FromBase64String ( $sharedKey ) $sha256 = New-Object System . Security . Cryptography . HMACSHA256 $sha256 . Key = $keyBytes $calculatedHash = $sha256 . ComputeHash ( $bytesToHash ) $encodedHash = [Convert] :: ToBase64String ( $calculatedHash ) $authorization = 'SharedKey {0}:{1}' -f $customerId , $encodedHash return $authorization } Function Post-LogAnalyticsData ( $ustomerId , $sharedKey , $body , $logType ) { $method = \"POST\" $contentType = \"application/json\" $resource = \"/api/logs\" $rfc1123date = [DateTime] :: UtcNow . ToString ( \"r\" ) $contentLength = $body . Length $signature = Build-Signature ` -customerId $customerId ` -sharedKey $sharedKey ` -date $rfc1123date ` -contentLength $contentLength ` -method $method ` -contentType $contentType ` -resource $resource $uri = \"https://\" + $customerId + \".ods.opinsights.azure.com\" + $resource + \"?api-version=2016-04-01\" $headers = @{ \"Authorization\" = $signature ; \"Log-Type\" = $logType ; \"x-ms-date\" = $rfc1123date ; \"time-generated-field\" = \"timestamp\" ; } $response = Invoke-WebRequest -Uri $uri -Method $method -ContentType $contentType -Headers $headers -Body $body -UseBasicParsing return $response . StatusCode } $LogType = \"AzureDevOps\" $Conn = Get-AutomationConnection -Name AzureRunAsConnection Connect-AzAccount -ServicePrincipal -Tenant $Conn . TenantID -ApplicationId $Conn . ApplicationID -CertificateThumbprint $Conn . CertificateThumbprint | Out-Null Select-AzSubscription -SubscriptionId $Conn . SubscriptionID | Out-Null $KeyVaultName = Get-AutomationVariable -Name KeyVaultName Write-Output -InputObject 'Get keyvault name from automation account variables - success' $OrganizationName = Get-AutomationVariable -Name OrganizationName Write-Output -InputObject 'Get Azure DevOps organization name from automation account variables - success' $CustomerId = Get-AutomationVariable -Name WorkspaceId Write-Output -InputObject 'Get Log Analytics Workspace Id from automation account variables - success' $LogAnalyticsWorkspace = Get-AzOperationalInsightsWorkspace | Where-Object -Property CustomerId -EQ $CustomerId $SharedKey = ( Get-AzOperationalInsightsWorkspaceSharedKey -ResourceGroupName $logAnalyticsWorkspace . ResourceGroupName -Name $logAnalyticsWorkspace . Name ). PrimarySharedKey Write-Output -InputObject \"Get shared key directly from ' $( $logAnalyticsWorkspace . Name ) - success\" $PersonAccessToken = ( Get-AzKeyVaultSecret -VaultName $KeyVaultName -Name 'AzureDevOpsPersonalAccessToken' ). SecretValueText Write-Output -InputObject \"Get Personal Access Token from key vault ' $( $KeyVaultName ) ' - success\" $StartTime = Get-AutomationVariable -Name LastAzureDevOpsSyncDate $StartTime = $StartTime . ToUniversalTime (). GetDateTimeFormats ( \"o\" ) [string] $EndTimeQuery = [DateTime] :: Now . ToUniversalTime (). GetDateTimeFormats ( \"o\" ) Write-Output -InputObject \"Script will look for audi events created between $( $StartTime ) and $( $endTimeQuery ) \" $Base64AuthInfo = [Convert] :: ToBase64String ( [Text.Encoding] :: ASCII . GetBytes (( \"{0}:{1}\" -f 'basic' , $PersonAccessToken ))) $Headers = @{ Authorization = \"Basic $Base64AuthInfo\" } [array] $ApiOutputs = @() [string] $ContinuationToken = '' do { $EndpointUri = \"https://auditservice.dev.azure.com/ $( $OrganizationName ) /_apis/audit/auditlog?api-version=5.1-preview.1\" $EndpointUri += \"&batchSize=200\" $EndpointUri += \"&skipAggregation=true\" $EndpointUri += \"&startTime= $( $StartTime ) \" $EndpointUri += \"&endTime= $( $endTimeQuery ) \" if ( $ContinuationToken ) { $EndpointUri += \"&continuationToken= $( $continuationToken ) \" } $ApiOutput = Invoke-RestMethod -Uri $endpointUri -Headers $headers -Method Get $ContinuationToken = $ApiOutput . continuationToken #tu $ApiOutputs += $ApiOutput } while ( $ApiOutput . hasMore ) [array] $DecoratedAuditLogEntries = $ApiOutputs . decoratedAuditLogEntries if ( -not $DecoratedAuditLogEntries ) { Write-Output -InputObject 'There are no new audit logs.' return ; } Write-Output -InputObject \"Found $( $DecoratedAuditLogEntries . Count ) new audit entries\" foreach ( $item in $DecoratedAuditLogEntries ) { $item . data = $item . data | ConvertTo-Json -Compress -Depth 100 } $RecordsJson = $DecoratedAuditLogEntries | ` Select-Object -ExcludeProperty actorImageUrl | ` ConvertTo-Json $StatusCode = Post-LogAnalyticsData -customerId $CustomerId -sharedKey $SharedKey -body ( [System.Text.Encoding] :: UTF8 . GetBytes ( $recordsJson )) -logType $LogType if ( $StatusCode -eq 200 ){ Set-AutomationVariable -Name LastAzureDevOpsSyncDate -Value $endTimeQuery Write-Output -InputObject 'Azure DevOps audi logs forwarding completed successfully' }","title":"Powershell Runbook"},{"location":"azure-devops-audit-logs-forwarding/#its-time-to-rest-and-check-what-we-did","text":"You've just discovered new extension installed. You wonder who and when did install this AzSK Extension, so you ask Log Analytics. AzureDevOps_CL | sort by TimeGenerated desc nulls last | where actionId_s == \"Extension.Installed\" | project TimeGenerated, actionId_s, scopeDisplayName_s , details_s, actorDisplayName_s TimeGenerated actionId_s scopeDisplayName_s details_s actorDisplayName_s 2020-03-15T16:47:19.367Z Extension.Installed AutomationGuyIO (Organization) Extension \"Secure DevOps Kit (AzSK) CICD Extensions for Azure\" from publisher \"Microsoft DevLabs\" was installed - Version \"3.1.7\" Automation Guru","title":"It's time to rest and check what we did"},{"location":"azure-devops-audit-logs-forwarding/#solution-development-insights","text":"ARA becomes a Contributor by default. Consider changing that. Storing LAW SharedKey in AKV is one of the options, but it'll force you to update it on change. We decided to get it directly during the script execution. We could use AAA encrypted value to store PAT, but in case of storing secrets, AKV should always be the primary choice. Other parameters we don't consider as secrets, so we store them in AAA variables. Enabling Allow trusted Microsoft services to bypass this firewall in AKW Networking configuration didn't allow access from AAA. Therefore we set this setting to Allow access from all networks .","title":"Solution development insights"},{"location":"azure-devops-audit-logs-forwarding/#visit-also","text":"Dominic Batstone's Blog: Export ADO Audit Logs and query them with LogParser mohitgoyal.co: Working with Audit logs in Azure DevOps","title":"Visit also"},{"location":"azure-lighthouse-configuration/","text":"Azure Lighthouse configuration Why should you read this article? What are the benefits? You want to manage all your customer in one place. You don't want to switch between subscriptions or between accounts. You want to manage access to specific customer roles without asking each time customer to do that. You are awesome managed service provider who is using best services in Azure in order to do that. High Level overview From Service provider team perspective Service provider tenant user which is added to proper group get access to My Cusotmers tab in Azure Lighthouse Can see all customers which are assigned to him. Can check AAD Group Membership and related role at the customer destination subscription. Can check access to customer resource From customer perspective Customer get access to new tab in Azure Lighthouse Service Providers Can see all service providers Display exact delegations for each provider Check offer details and correlated assigned role Prerequisites Az PowerShell Module installed Account with Owner role in customer tenant Access to create and configure Azure Active Directory groups in Manged Service Provider tenant Service Provider ARM template To deploy desired configuration in customer tenant below template must be used. In such ARM template we basically do the mapping between groups created earlier in Azure AD of Managed Service Provider tenant and role IDs defined in customer tenant. To check role defintion ID use Powershell command ( Get-AzRoleDefinition -Name \"Name_of_the_role\" ). Id To check Azure Active Directory group ID use Powershell command ( Get-AzADGroup -Name \"Name_of_the_AAD_group\" ). ObjectId If you don't have yet groups created you can simply create them with following script: param ( $TenantID , $CustomerName ) Connect-AzAccount -Tenant $TenantID $groups = @( \"Logs-Reader\" , \"Customer-Reader\" , \"Customer-Contributor\" ) foreach ( $group in $groups ) { $groupName = \"Lighthouse-$CustomerName-$group\" $aadGroup = Get-AzADGroup -DisplayName $groupName if ( $aadGroup ) { Write-Output \"Group $groupName already exists.\" } else { Try { New-AzADGroup -DisplayName $groupName -MailNickname $groupName Start-Sleep -s 5 $aadGroup = ( Get-AzADGroup -DisplayName $groupName ). ObjectId Write-Output \"AAD Group $groupName with id $aadGroupId created with success\" } Catch { Write-Output \"Unexpected error occured during AAD group creation. Error: $( $_ . exception . Message ) \" } } } Here you can find short description of each parameter in ARM: mspOfferName - name of the offer from the Managed Service Provider mspOfferDescription - name of the Managed Service Provider offering managedByTenantId - Managed Service Provider tenant ID authorizations - in this part you should provide array according to how you want to configure access in Azure Lighthouse. \"parameters\": { \"mspOfferName\": { \"value\": \"\" }, \"mspOfferDescription\": { \"value\": \"\" }, \"managedByTenantId\": { \"value\": \"\" }, \"authorizations\": { \"value\": [ { \"principalId\": \"000000-0000-00000-0000-0000000\", \"principalIdDisplayName\": \"Logs Reader\", \"roleDefinitionId\": \"73c42c96-874c-492b-b04d-ab87d138a893\" }, { \"principalId\": \"000000-0000-00000-0000-0000000\", \"principalIdDisplayName\": \"Customer Reader\", \"roleDefinitionId\": \"acdd72a7-3385-48ef-bd42-f606fba81ae7\" }, { \"principalId\": \"000000-0000-00000-0000-0000000\", \"principalIdDisplayName\": \"Customer Contributor\", \"roleDefinitionId\": \"b24988ac-6180-42a0-ab88-20f7382dd24c\" } ] } } In order to deploy such ARM you can simply use New-AzDeployment from PowerShell Az module. IMPORTANT! Remember that you must be logged to customer tenant to deploy ARM template, not Managed Service Provider tenant. Things to have in mind before applying this solution Decide how you want to manage access to your customers. Do you want to have same groups for all of them or separate one? Decide which roles are necessary for you and split them correctly - you can always do it later however it's best to have solution ready from the beginning.","title":"Azure Lighthouse Configuration"},{"location":"azure-lighthouse-configuration/#azure-lighthouse-configuration","text":"","title":"Azure Lighthouse configuration"},{"location":"azure-lighthouse-configuration/#why-should-you-read-this-article-what-are-the-benefits","text":"You want to manage all your customer in one place. You don't want to switch between subscriptions or between accounts. You want to manage access to specific customer roles without asking each time customer to do that. You are awesome managed service provider who is using best services in Azure in order to do that.","title":"Why should you read this article? What are the benefits?"},{"location":"azure-lighthouse-configuration/#high-level-overview","text":"","title":"High Level overview"},{"location":"azure-lighthouse-configuration/#from-service-provider-team-perspective","text":"Service provider tenant user which is added to proper group get access to My Cusotmers tab in Azure Lighthouse Can see all customers which are assigned to him. Can check AAD Group Membership and related role at the customer destination subscription. Can check access to customer resource","title":"From Service provider team perspective"},{"location":"azure-lighthouse-configuration/#from-customer-perspective","text":"Customer get access to new tab in Azure Lighthouse Service Providers Can see all service providers Display exact delegations for each provider Check offer details and correlated assigned role","title":"From customer perspective"},{"location":"azure-lighthouse-configuration/#prerequisites","text":"Az PowerShell Module installed Account with Owner role in customer tenant Access to create and configure Azure Active Directory groups in Manged Service Provider tenant","title":"Prerequisites"},{"location":"azure-lighthouse-configuration/#service-provider-arm-template","text":"To deploy desired configuration in customer tenant below template must be used. In such ARM template we basically do the mapping between groups created earlier in Azure AD of Managed Service Provider tenant and role IDs defined in customer tenant. To check role defintion ID use Powershell command ( Get-AzRoleDefinition -Name \"Name_of_the_role\" ). Id To check Azure Active Directory group ID use Powershell command ( Get-AzADGroup -Name \"Name_of_the_AAD_group\" ). ObjectId If you don't have yet groups created you can simply create them with following script: param ( $TenantID , $CustomerName ) Connect-AzAccount -Tenant $TenantID $groups = @( \"Logs-Reader\" , \"Customer-Reader\" , \"Customer-Contributor\" ) foreach ( $group in $groups ) { $groupName = \"Lighthouse-$CustomerName-$group\" $aadGroup = Get-AzADGroup -DisplayName $groupName if ( $aadGroup ) { Write-Output \"Group $groupName already exists.\" } else { Try { New-AzADGroup -DisplayName $groupName -MailNickname $groupName Start-Sleep -s 5 $aadGroup = ( Get-AzADGroup -DisplayName $groupName ). ObjectId Write-Output \"AAD Group $groupName with id $aadGroupId created with success\" } Catch { Write-Output \"Unexpected error occured during AAD group creation. Error: $( $_ . exception . Message ) \" } } } Here you can find short description of each parameter in ARM: mspOfferName - name of the offer from the Managed Service Provider mspOfferDescription - name of the Managed Service Provider offering managedByTenantId - Managed Service Provider tenant ID authorizations - in this part you should provide array according to how you want to configure access in Azure Lighthouse. \"parameters\": { \"mspOfferName\": { \"value\": \"\" }, \"mspOfferDescription\": { \"value\": \"\" }, \"managedByTenantId\": { \"value\": \"\" }, \"authorizations\": { \"value\": [ { \"principalId\": \"000000-0000-00000-0000-0000000\", \"principalIdDisplayName\": \"Logs Reader\", \"roleDefinitionId\": \"73c42c96-874c-492b-b04d-ab87d138a893\" }, { \"principalId\": \"000000-0000-00000-0000-0000000\", \"principalIdDisplayName\": \"Customer Reader\", \"roleDefinitionId\": \"acdd72a7-3385-48ef-bd42-f606fba81ae7\" }, { \"principalId\": \"000000-0000-00000-0000-0000000\", \"principalIdDisplayName\": \"Customer Contributor\", \"roleDefinitionId\": \"b24988ac-6180-42a0-ab88-20f7382dd24c\" } ] } } In order to deploy such ARM you can simply use New-AzDeployment from PowerShell Az module. IMPORTANT! Remember that you must be logged to customer tenant to deploy ARM template, not Managed Service Provider tenant.","title":"Service Provider ARM template"},{"location":"azure-lighthouse-configuration/#things-to-have-in-mind-before-applying-this-solution","text":"Decide how you want to manage access to your customers. Do you want to have same groups for all of them or separate one? Decide which roles are necessary for you and split them correctly - you can always do it later however it's best to have solution ready from the beginning.","title":"Things to have in mind before applying this solution"},{"location":"copy-database-between-stages/","text":"Copy Azure database between stages Goal of this article is to show you how to easily migrate database between two Azure SQL Servers. It can be usefull in scenarios where you need to have exact configuration on two environments and want to have it done in automatic way. However you should bear in mind that for big size databases process of migration can take quite long. What services are needed to have solution working properly? The only service which is mandatory (besides two Azure SQL Servers) is Azure Storage Account, on which bacpac files will be stored. It's up to you how you will configure this storage, as there aren't any specific requirement. How the process of migration looks like? As you probably saw on main picture of this article the process is quite easy: Script initialize connection to source database. Script is starting export of bacpac file from source database to storage account. Script checks if bacpac was properly created. Script is starting import of bacpac file to destination database from storage account. Script validate if process of importing bacpac file finished with success. Prerequisites Az module installed on platform on which script will be run (eg. your local PC, Azure DevOps pipeline, Azure Automation) Install-Module -Name Az -Force Firewall rule added on SQL Server (if you are using local PC) or option \"Allow Azure services and resources to access this server\" in case you use some other Azure service to run the script. Blob container called \"bacpacs\" created on storage account. Account/Service Prinicipal under which script will work should have proper permission (Contributor) assigned to storage account. Script: Copy database between stages Source Code param ( $sourceSqlUser , $sourceSubscriptionID , $sourceSqlServerResourceGroup , $sourceSqlServerName , $sourceSqlDatabaseName , $destinationDatabaseEdition , $destinationServiceObjectiveName , $destinationDatabaseMaxSizeBytes , $destinationSqlUser , $destinationSubscriptionID , $destinationSqlServerResourceGroup , $destinationSqlServerName , $destinationSqlDatabaseName , $commonSubscriptionId , $storageAccountName , $storageAccountResourceGroup , $keyVaultName , $sqlServerSourceKeyVaultEntry , $sqlServerDestinationKeyVaultEntry , $tenantId ) Connect-AzAccount -TenantId $tenantId Select-AzSubscription -SubscriptionId $commonSubscriptionID | Out-Null $blobUrl = ( Get-AzStorageAccount -ResourceGroupName $storageAccountResourceGroup -Name $storageAccountName | Select-Object *). Context . BlobEndpoint $storageAccountKey = ( Get-AzStorageAccountKey -ResourceGroupName $storageAccountResourceGroup -Name $storageAccountName )[ 0 ]. Value $sourceSqlServerPassword = ( Get-AzKeyVaultSecret -VaultName $keyVaultName -Name $sqlServerSourceKeyVaultEntry ). SecretValue $destinationSqlServerPassword = ( Get-AzKeyVaultSecret -VaultName $KeyVaultName -Name $sqlServerDestinationKeyVaultEntry ). SecretValue Select-AzSubscription -SubscriptionId $sourceSubscriptionID | Out-Null Try { Get-AzSqlDatabase -DatabaseName $sourceSqlDatabaseName -ServerName $sourceSqlServerName -ResourceGroupName $sourceSqlServerResourceGroup Write-Output \"Found $sourceSqlDatabaseName database on SQL Server $sourceSqlServerName\" } Catch { Write-Output \"Database $sourceSqlDatabaseName can not be found on SQL Server $sourceSqlServerName\" exit } $date = Get-Date -Format yyyyMMdd $url = $blobUrl + \"bacpacs/$sourceSqlDatabaseName_$date.bacpac\" $exportRequest = New-AzSqlDatabaseExport -DatabaseName $sourceSqlDatabaseName -ResourceGroupName $sourceSqlServerResourceGroup -ServerName $sourceSqlServerName -StorageKeyType \"StorageAccessKey\" -StorageUri $url -StorageKey $shdStorageAccountKey -AdministratorLogin $sourceSqlUser -AdministratorLoginPassword $sourceSqlServerPassword $exportStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $exportRequest . OperationStatusLink Write-Output \"Exporting database $sourceSqlDatabaseName to bacpac file\" while ( $exportStatus . Status -eq \"InProgress\" ) { Start-Sleep -s 10 $exportStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $exportRequest . OperationStatusLink Write-Output \"Exporting...\" } Write-Output \"Proceeding with destination database...\" Select-AzSubscription -SubscriptionId $destinationSubscriptionID | Out-Null if ( $exportStatus . Status -eq \"Succeeded\" ) { Write-Output \"Database $sourceSqlDatabaseName export to bacpac file finished with success.\" $targetDatabase = Get-AzSqlDatabase -DatabaseName $destinationSqlDatabaseName -ResourceGroupName $destinationSqlServerResourceGroup -ServerName $destinationSqlServerName if ( $targetDatabase ) { Try { Write-Output \"Removing database $destinationSqlDatabaseName on target server as it already exist.\" Remove-AzSqlDatabase -DatabaseName $destinationSqlDatabaseName -ResourceGroupName $destinationSqlServerResourceGroup -ServerName $destinationSqlServerName Write-Output \"Database $destinationSqlDatabaseName removal finished with success\" } Catch { Write-Output \"Unexpected error occured during removal of database $destinationSqlDatabaseName from server $destinationSqlServerName . Error: $( $_ . Exception . Message ) \" } } $importRequest = New-AzSqlDatabaseImport -DatabaseName $destinationSqlDatabaseName -ResourceGroupName $destinationSqlServerResourceGroup -ServerName $destinationSqlServerName -StorageKeyType \"StorageAccessKey\" -StorageUri $url -StorageKey $storageAccountKey -AdministratorLogin $destinationSqlUser -AdministratorLoginPassword $destinationSqlServerPassword -Edition $destinationDatabaseEdition -ServiceObjectiveName $destinationServiceObjectiveName -DatabaseMaxSizeBytes $destinationDatabaseMaxSizeBytes $importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest . OperationStatusLink Write-Output \"Importing database $destinationSqlDatabaseName from bacpac file\" while ( $importStatus . Status -eq \"InProgress\" ) { Start-Sleep -s 10 $importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest . OperationStatusLink Write-Output \"Importing...\" } if ( $importStatus . Status -eq \"Succeeded\" ) { Write-Output \"Database $destinationSqlDatabaseName import finished with success.\" } else { Write-Output \"Import of database $destinationSqlDatabaseName to SQL server $destinationSqlServerName failed. Error: $( $importStatus . StatusMessage ) \" } } else { Write-Output \"Export of database $destinationSqlDatabaseName from SQL server $destinationSqlServerName failed. Error: $( $exportStatus . StatusMessage ) \" } Things to have in mind before applying this solution Script will automatically remove database in the destination if it already exist, ensure that it can be done before running script. Check if database can be copied to different SQL server as it can contain some data which are sensitive and should be used only in specific environment. Ensure that provided secrets names are created and you have proper access policy configured for you account/service principal.","title":"Copy Azure database between stages"},{"location":"copy-database-between-stages/#copy-azure-database-between-stages","text":"Goal of this article is to show you how to easily migrate database between two Azure SQL Servers. It can be usefull in scenarios where you need to have exact configuration on two environments and want to have it done in automatic way. However you should bear in mind that for big size databases process of migration can take quite long.","title":"Copy Azure database between stages"},{"location":"copy-database-between-stages/#what-services-are-needed-to-have-solution-working-properly","text":"The only service which is mandatory (besides two Azure SQL Servers) is Azure Storage Account, on which bacpac files will be stored. It's up to you how you will configure this storage, as there aren't any specific requirement.","title":"What services are needed to have solution working properly?"},{"location":"copy-database-between-stages/#how-the-process-of-migration-looks-like","text":"As you probably saw on main picture of this article the process is quite easy: Script initialize connection to source database. Script is starting export of bacpac file from source database to storage account. Script checks if bacpac was properly created. Script is starting import of bacpac file to destination database from storage account. Script validate if process of importing bacpac file finished with success.","title":"How the process of migration looks like?"},{"location":"copy-database-between-stages/#prerequisites","text":"Az module installed on platform on which script will be run (eg. your local PC, Azure DevOps pipeline, Azure Automation) Install-Module -Name Az -Force Firewall rule added on SQL Server (if you are using local PC) or option \"Allow Azure services and resources to access this server\" in case you use some other Azure service to run the script. Blob container called \"bacpacs\" created on storage account. Account/Service Prinicipal under which script will work should have proper permission (Contributor) assigned to storage account.","title":"Prerequisites"},{"location":"copy-database-between-stages/#script","text":"Copy database between stages Source Code param ( $sourceSqlUser , $sourceSubscriptionID , $sourceSqlServerResourceGroup , $sourceSqlServerName , $sourceSqlDatabaseName , $destinationDatabaseEdition , $destinationServiceObjectiveName , $destinationDatabaseMaxSizeBytes , $destinationSqlUser , $destinationSubscriptionID , $destinationSqlServerResourceGroup , $destinationSqlServerName , $destinationSqlDatabaseName , $commonSubscriptionId , $storageAccountName , $storageAccountResourceGroup , $keyVaultName , $sqlServerSourceKeyVaultEntry , $sqlServerDestinationKeyVaultEntry , $tenantId ) Connect-AzAccount -TenantId $tenantId Select-AzSubscription -SubscriptionId $commonSubscriptionID | Out-Null $blobUrl = ( Get-AzStorageAccount -ResourceGroupName $storageAccountResourceGroup -Name $storageAccountName | Select-Object *). Context . BlobEndpoint $storageAccountKey = ( Get-AzStorageAccountKey -ResourceGroupName $storageAccountResourceGroup -Name $storageAccountName )[ 0 ]. Value $sourceSqlServerPassword = ( Get-AzKeyVaultSecret -VaultName $keyVaultName -Name $sqlServerSourceKeyVaultEntry ). SecretValue $destinationSqlServerPassword = ( Get-AzKeyVaultSecret -VaultName $KeyVaultName -Name $sqlServerDestinationKeyVaultEntry ). SecretValue Select-AzSubscription -SubscriptionId $sourceSubscriptionID | Out-Null Try { Get-AzSqlDatabase -DatabaseName $sourceSqlDatabaseName -ServerName $sourceSqlServerName -ResourceGroupName $sourceSqlServerResourceGroup Write-Output \"Found $sourceSqlDatabaseName database on SQL Server $sourceSqlServerName\" } Catch { Write-Output \"Database $sourceSqlDatabaseName can not be found on SQL Server $sourceSqlServerName\" exit } $date = Get-Date -Format yyyyMMdd $url = $blobUrl + \"bacpacs/$sourceSqlDatabaseName_$date.bacpac\" $exportRequest = New-AzSqlDatabaseExport -DatabaseName $sourceSqlDatabaseName -ResourceGroupName $sourceSqlServerResourceGroup -ServerName $sourceSqlServerName -StorageKeyType \"StorageAccessKey\" -StorageUri $url -StorageKey $shdStorageAccountKey -AdministratorLogin $sourceSqlUser -AdministratorLoginPassword $sourceSqlServerPassword $exportStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $exportRequest . OperationStatusLink Write-Output \"Exporting database $sourceSqlDatabaseName to bacpac file\" while ( $exportStatus . Status -eq \"InProgress\" ) { Start-Sleep -s 10 $exportStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $exportRequest . OperationStatusLink Write-Output \"Exporting...\" } Write-Output \"Proceeding with destination database...\" Select-AzSubscription -SubscriptionId $destinationSubscriptionID | Out-Null if ( $exportStatus . Status -eq \"Succeeded\" ) { Write-Output \"Database $sourceSqlDatabaseName export to bacpac file finished with success.\" $targetDatabase = Get-AzSqlDatabase -DatabaseName $destinationSqlDatabaseName -ResourceGroupName $destinationSqlServerResourceGroup -ServerName $destinationSqlServerName if ( $targetDatabase ) { Try { Write-Output \"Removing database $destinationSqlDatabaseName on target server as it already exist.\" Remove-AzSqlDatabase -DatabaseName $destinationSqlDatabaseName -ResourceGroupName $destinationSqlServerResourceGroup -ServerName $destinationSqlServerName Write-Output \"Database $destinationSqlDatabaseName removal finished with success\" } Catch { Write-Output \"Unexpected error occured during removal of database $destinationSqlDatabaseName from server $destinationSqlServerName . Error: $( $_ . Exception . Message ) \" } } $importRequest = New-AzSqlDatabaseImport -DatabaseName $destinationSqlDatabaseName -ResourceGroupName $destinationSqlServerResourceGroup -ServerName $destinationSqlServerName -StorageKeyType \"StorageAccessKey\" -StorageUri $url -StorageKey $storageAccountKey -AdministratorLogin $destinationSqlUser -AdministratorLoginPassword $destinationSqlServerPassword -Edition $destinationDatabaseEdition -ServiceObjectiveName $destinationServiceObjectiveName -DatabaseMaxSizeBytes $destinationDatabaseMaxSizeBytes $importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest . OperationStatusLink Write-Output \"Importing database $destinationSqlDatabaseName from bacpac file\" while ( $importStatus . Status -eq \"InProgress\" ) { Start-Sleep -s 10 $importStatus = Get-AzSqlDatabaseImportExportStatus -OperationStatusLink $importRequest . OperationStatusLink Write-Output \"Importing...\" } if ( $importStatus . Status -eq \"Succeeded\" ) { Write-Output \"Database $destinationSqlDatabaseName import finished with success.\" } else { Write-Output \"Import of database $destinationSqlDatabaseName to SQL server $destinationSqlServerName failed. Error: $( $importStatus . StatusMessage ) \" } } else { Write-Output \"Export of database $destinationSqlDatabaseName from SQL server $destinationSqlServerName failed. Error: $( $exportStatus . StatusMessage ) \" }","title":"Script:"},{"location":"copy-database-between-stages/#things-to-have-in-mind-before-applying-this-solution","text":"Script will automatically remove database in the destination if it already exist, ensure that it can be done before running script. Check if database can be copied to different SQL server as it can contain some data which are sensitive and should be used only in specific environment. Ensure that provided secrets names are created and you have proper access policy configured for you account/service principal.","title":"Things to have in mind before applying this solution"},{"location":"powershell-web-browser-automation/","text":"Web browser automation with Powershell & Selenium After reading this article, you should be able to write a basic web-automation script on your own. We hope you already have an idea where you want to use it. $cred = Get-Credential .\\ New-AzPayAsYouGoSubscription . ps1 -Credentials $cred Important Although this article shows how to automate creating a new PAYG subscription, it's goal is to present web automation with PowerShell and Selenium. Please consider the example script as a byproduct. First of all: it's easy! You need Powershell Selenium module from Powershell Gallery . Install-Module -Name Selenium -RequiredVersion 2 . 3 . 1 Every single step of the entire automation process is more or less: Navigation to URL. Waiting for one or more element/s like input, button, etc. to appear. Doing action: filling a form, clicking a button, etc. * Steps 2 and 3 require you to know the way to identify elements. How to navigate to URL? $Url = 'http://example.com' $Driver = Start-SeChrome Enter-SeUrl -Driver $Driver -Url $Url How to identify elements? Use developer tools included in your web browser. I use chrome. After clicking right on an element of interest, you need to select inspect. Then you'll get details and can decide whether to identify an item by id, class, etc. $UsernameElementName = 'loginfmt' $NameElement = Find-SeElement -Driver $Driver -Name $UsernameElementName How to wait for the element to appear? Any user knows that you need to see the button before you can click it. The same goes here. $PaygPlanElementClassName = 'plan_type_consumption' $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName while ( -not $PaygPlanElement ) { Write-Host -Object \"Waiting for element class $( $PaygPlanElementClassName ) \" Start-Sleep -Seconds 1 $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName $PaygPlanElementClassName } How to perform item-sepcific action? $PasswordElement = Find-SeElement -Driver $Driver -Name 'passwd' while ( -not $PasswordElement ) { Start-Sleep -Seconds 1 $PasswordElement = Find-SeElement -Driver $Driver -Name 'passwd' } Send-SeKeys -Element $PasswordElement -Keys $Credentials . GetNetworkCredential (). Password ( Find-SeElement -Driver $Driver -Id 'idSIButton9' ). Click () Do you want to perform more than one 'wait and click' operations in a row? Use the following method if there is a need to perform the same action on elements that can be selected by the same property. $ElementsToClick = @( 'card-submit-button' , 'no-support-option' , 'attach-support-button' ) foreach ( $elementId in $ElementsToClick ) { do { $Element = Find-SeElement -Driver $Driver -Id $elementId if ( $Element ){ try { $Element . Click () } catch { $Element = $null } } else { Write-Host -Object \"Waiting for element id $( $elementId ) \" Start-Sleep -Seconds 1 } } while ( -not $Element ) } Script https://github.com/automationgurus/automationgurus.github.io/blob/master/src/code/New-AzPayAsYouGoSubscription.ps1 param ( $Credentials ) Write-Host -Object \"Start\" $Url = \"https://account.azure.com/signup?showCatalog=True&appId=Ibiza_SubscriptionsOverviewBladeCommandBar\" $Driver = Start-SeChrome Enter-SeUrl -Driver $Driver -Url $Url #Enter username $UsernameElementName = 'loginfmt' $UsernameElement = Find-SeElement -Driver $Driver -Name $UsernameElementName while ( -not $UsernameElement ) { Write-Host -Object \"Waiting for element $( $UsernameElementName ) \" Start-Sleep -Seconds 1 $UsernameElement = Find-SeElement -Driver $Driver -Name $UsernameElementName } Send-SeKeys -Element $UsernameElement -Keys $Credentials . UserName ( Find-SeElement -Driver $Driver -Id 'idSIButton9' ). Click () #Select 'Personal Account' $PersonalAccountElement = Find-SeElement -Driver $Driver -Id 'msaTile' while ( -not $PersonalAccountElement ) { Start-Sleep -Seconds 1 $PersonalAccountElement = Find-SeElement -Driver $Driver -Id 'msaTile' } $PersonalAccountElement . Click () #Enter password $PasswordElementName = 'passwd' $PasswordElement = Find-SeElement -Driver $Driver -Name $PasswordElementName while ( -not $PasswordElement ) { Write-Host -Object \"Waiting for element name $( $PasswordElementName ) \" Start-Sleep -Seconds 1 $PasswordElement = Find-SeElement -Driver $Driver -Name $PasswordElementName } Send-SeKeys -Element $PasswordElement -Keys $Credentials . GetNetworkCredential (). Password ( Find-SeElement -Driver $Driver -Id 'idSIButton9' ). Click () #Select PAYG Plan $PaygPlanElementClassName = 'plan_type_consumption' $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName $PaygPlanElementClassName | Where-Object -Property Text -like '*Pay-As-You-Go*' while ( -not $PaygPlanElement ) { Write-Host -Object \"Waiting for element class $( $PaygPlanElementClassName ) \" Start-Sleep -Seconds 1 $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName $PaygPlanElementClassName | Where-Object -Property Text -like '*Pay-As-You-Go*' } $PaygPlanElement . Click () #Set Payment and support agreement $ElementsToClick = @( 'card-submit-button' , 'no-support-option' , 'attach-support-button' ) foreach ( $elementId in $ElementsToClick ) { do { $Element = Find-SeElement -Driver $Driver -Id $elementId if ( $Element ){ try { $Element . Click () } catch { $Element = $null } } else { Write-Host -Object \"Waiting for element id $( $elementId ) \" Start-Sleep -Seconds 1 } } while ( -not $Element ) } #Accept terms $AgreeElementId = 'accept-terms-checkbox' $AgreeElement = Find-SeElement -Driver $Driver -Id $AgreeElementId while ( -not $AgreeElement ) { Write-Host -Object \"Waiting for element id $( $AgreeElementId ) \" Start-Sleep -Seconds 1 $AgreeElement = Find-SeElement -Driver $Driver -Id $AgreeElementId } Send-SeKeys -Element $AgreeElement -Keys ' ' #Create subscription $AcceptElementId = 'accept-terms-submit-button' do { $AcceptElement = Find-SeElement -Driver $Driver -Id $AcceptElementId if ( $AcceptElement ){ try { $AcceptElement . Click () } catch { $AcceptElement = $null } } else { Write-Host -Object \"Waiting for element id $( $AcceptElementId ) \" Start-Sleep -Seconds 1 } } while ( -not $AcceptElement ) Write-Host -Object \"End\"","title":"Powershell Web-Based Automation"},{"location":"powershell-web-browser-automation/#web-browser-automation-with-powershell-selenium","text":"After reading this article, you should be able to write a basic web-automation script on your own. We hope you already have an idea where you want to use it. $cred = Get-Credential .\\ New-AzPayAsYouGoSubscription . ps1 -Credentials $cred","title":"Web browser automation with Powershell &amp; Selenium"},{"location":"powershell-web-browser-automation/#important","text":"Although this article shows how to automate creating a new PAYG subscription, it's goal is to present web automation with PowerShell and Selenium. Please consider the example script as a byproduct.","title":"Important"},{"location":"powershell-web-browser-automation/#first-of-all-its-easy","text":"You need Powershell Selenium module from Powershell Gallery . Install-Module -Name Selenium -RequiredVersion 2 . 3 . 1 Every single step of the entire automation process is more or less: Navigation to URL. Waiting for one or more element/s like input, button, etc. to appear. Doing action: filling a form, clicking a button, etc. * Steps 2 and 3 require you to know the way to identify elements.","title":"First of all: it's easy!"},{"location":"powershell-web-browser-automation/#how-to-navigate-to-url","text":"$Url = 'http://example.com' $Driver = Start-SeChrome Enter-SeUrl -Driver $Driver -Url $Url","title":"How to navigate to URL?"},{"location":"powershell-web-browser-automation/#how-to-identify-elements","text":"Use developer tools included in your web browser. I use chrome. After clicking right on an element of interest, you need to select inspect. Then you'll get details and can decide whether to identify an item by id, class, etc. $UsernameElementName = 'loginfmt' $NameElement = Find-SeElement -Driver $Driver -Name $UsernameElementName","title":"How to identify elements?"},{"location":"powershell-web-browser-automation/#how-to-wait-for-the-element-to-appear","text":"Any user knows that you need to see the button before you can click it. The same goes here. $PaygPlanElementClassName = 'plan_type_consumption' $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName while ( -not $PaygPlanElement ) { Write-Host -Object \"Waiting for element class $( $PaygPlanElementClassName ) \" Start-Sleep -Seconds 1 $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName $PaygPlanElementClassName }","title":"How to wait for the element to appear?"},{"location":"powershell-web-browser-automation/#how-to-perform-item-sepcific-action","text":"$PasswordElement = Find-SeElement -Driver $Driver -Name 'passwd' while ( -not $PasswordElement ) { Start-Sleep -Seconds 1 $PasswordElement = Find-SeElement -Driver $Driver -Name 'passwd' } Send-SeKeys -Element $PasswordElement -Keys $Credentials . GetNetworkCredential (). Password ( Find-SeElement -Driver $Driver -Id 'idSIButton9' ). Click ()","title":"How to perform item-sepcific action?"},{"location":"powershell-web-browser-automation/#do-you-want-to-perform-more-than-one-wait-and-click-operations-in-a-row","text":"Use the following method if there is a need to perform the same action on elements that can be selected by the same property. $ElementsToClick = @( 'card-submit-button' , 'no-support-option' , 'attach-support-button' ) foreach ( $elementId in $ElementsToClick ) { do { $Element = Find-SeElement -Driver $Driver -Id $elementId if ( $Element ){ try { $Element . Click () } catch { $Element = $null } } else { Write-Host -Object \"Waiting for element id $( $elementId ) \" Start-Sleep -Seconds 1 } } while ( -not $Element ) }","title":"Do you want to perform more than one 'wait and click' operations in a row?"},{"location":"powershell-web-browser-automation/#script","text":"https://github.com/automationgurus/automationgurus.github.io/blob/master/src/code/New-AzPayAsYouGoSubscription.ps1 param ( $Credentials ) Write-Host -Object \"Start\" $Url = \"https://account.azure.com/signup?showCatalog=True&appId=Ibiza_SubscriptionsOverviewBladeCommandBar\" $Driver = Start-SeChrome Enter-SeUrl -Driver $Driver -Url $Url #Enter username $UsernameElementName = 'loginfmt' $UsernameElement = Find-SeElement -Driver $Driver -Name $UsernameElementName while ( -not $UsernameElement ) { Write-Host -Object \"Waiting for element $( $UsernameElementName ) \" Start-Sleep -Seconds 1 $UsernameElement = Find-SeElement -Driver $Driver -Name $UsernameElementName } Send-SeKeys -Element $UsernameElement -Keys $Credentials . UserName ( Find-SeElement -Driver $Driver -Id 'idSIButton9' ). Click () #Select 'Personal Account' $PersonalAccountElement = Find-SeElement -Driver $Driver -Id 'msaTile' while ( -not $PersonalAccountElement ) { Start-Sleep -Seconds 1 $PersonalAccountElement = Find-SeElement -Driver $Driver -Id 'msaTile' } $PersonalAccountElement . Click () #Enter password $PasswordElementName = 'passwd' $PasswordElement = Find-SeElement -Driver $Driver -Name $PasswordElementName while ( -not $PasswordElement ) { Write-Host -Object \"Waiting for element name $( $PasswordElementName ) \" Start-Sleep -Seconds 1 $PasswordElement = Find-SeElement -Driver $Driver -Name $PasswordElementName } Send-SeKeys -Element $PasswordElement -Keys $Credentials . GetNetworkCredential (). Password ( Find-SeElement -Driver $Driver -Id 'idSIButton9' ). Click () #Select PAYG Plan $PaygPlanElementClassName = 'plan_type_consumption' $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName $PaygPlanElementClassName | Where-Object -Property Text -like '*Pay-As-You-Go*' while ( -not $PaygPlanElement ) { Write-Host -Object \"Waiting for element class $( $PaygPlanElementClassName ) \" Start-Sleep -Seconds 1 $PaygPlanElement = Find-SeElement -Driver $Driver -ClassName $PaygPlanElementClassName | Where-Object -Property Text -like '*Pay-As-You-Go*' } $PaygPlanElement . Click () #Set Payment and support agreement $ElementsToClick = @( 'card-submit-button' , 'no-support-option' , 'attach-support-button' ) foreach ( $elementId in $ElementsToClick ) { do { $Element = Find-SeElement -Driver $Driver -Id $elementId if ( $Element ){ try { $Element . Click () } catch { $Element = $null } } else { Write-Host -Object \"Waiting for element id $( $elementId ) \" Start-Sleep -Seconds 1 } } while ( -not $Element ) } #Accept terms $AgreeElementId = 'accept-terms-checkbox' $AgreeElement = Find-SeElement -Driver $Driver -Id $AgreeElementId while ( -not $AgreeElement ) { Write-Host -Object \"Waiting for element id $( $AgreeElementId ) \" Start-Sleep -Seconds 1 $AgreeElement = Find-SeElement -Driver $Driver -Id $AgreeElementId } Send-SeKeys -Element $AgreeElement -Keys ' ' #Create subscription $AcceptElementId = 'accept-terms-submit-button' do { $AcceptElement = Find-SeElement -Driver $Driver -Id $AcceptElementId if ( $AcceptElement ){ try { $AcceptElement . Click () } catch { $AcceptElement = $null } } else { Write-Host -Object \"Waiting for element id $( $AcceptElementId ) \" Start-Sleep -Seconds 1 } } while ( -not $AcceptElement ) Write-Host -Object \"End\"","title":"Script"},{"location":"worth-to-check/","text":"Udefull links","title":"Worth to check"},{"location":"worth-to-check/#udefull-links","text":"","title":"Udefull links"}]}